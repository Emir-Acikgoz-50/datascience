<h1>2.4. Jargon and Terminology</h1>

<h2>General</h2>

**Feature Engineering**: the process of creating or selecting features to possibly increase the predictive capabilities of a machine learning model.

**Data Pre-processing**: The process of transforming raw data, so that it can be used by machine learning models.

**Regression**: A kind of machine learning problem about the relationship between one dependent and one or multiple independent continous variables.  

**Underfitting**: A scenario where the model is too simple and is unable to fit the data. This leads to inaccurate predictions, even if predicted on the training data.

**Overfitting**: A scenario where the model fits the specifications of the train data too well. In this case, the model can’t get a grasp of a general pattern in the data, that is necessary to make predictions and may lead to a model performing terribly on unseen data (i.e “validation” data).

**Generalization**: the ability for a model to adapt properly on unseen data.

**Cross-validation**: a technique used to assess how the model generalises on an independent data set, seperate from the data set used to train the model.

<h2>Models</h2>

**Multivariate Lineair Regression**: a kind of linear regression model, where multiple independent variables are used to predict one dependent variable.
